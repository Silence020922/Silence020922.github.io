<!DOCTYPE html>
<html lang="en-US" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>FlashAttention | Silence's blog</title>
    <meta name="description" content="加速transormer模型训练速度，以便应用到较长上下文中。">
    <meta name="generator" content="VitePress v1.0.0-rc.31">
    <link rel="preload stylesheet" href="/assets/style.jx_1Qzz9.css" as="style">
    
    <script type="module" src="/assets/app.Hdd3U6_t.js"></script>
    <link rel="preload" href="/assets/inter-roman-latin.bvIUbFQP.woff2" as="font" type="font/woff2" crossorigin="">
    <link rel="modulepreload" href="/assets/chunks/framework.CP3Xps-Z.js">
    <link rel="modulepreload" href="/assets/chunks/theme.jkTH5RR0.js">
    <link rel="modulepreload" href="/assets/chunks/Page.qgDUVnsQ.js">
    <link rel="modulepreload" href="/assets/posts_FlashAttn.md.uZGWk_Tb.lean.js">
    <script id="check-dark-mode">(()=>{const e=localStorage.getItem("vitepress-theme-appearance")||"dark",a=window.matchMedia("(prefers-color-scheme: dark)").matches;(!e||e==="auto"?a:e==="dark")&&document.documentElement.classList.add("dark")})();</script>
    <script id="check-mac-os">document.documentElement.classList.toggle("mac",/Mac|iPhone|iPod|iPad/i.test(navigator.platform));</script>
  </head>
  <body>
    <div id="app"><!--[--><div class="Layout" data-v-9d8abc1e><!--[--><!--]--><!--[--><span tabindex="-1" data-v-c8291ffa></span><a href="#VPContent" class="VPSkipLink visually-hidden" data-v-c8291ffa> Skip to content </a><!--]--><!----><header class="VPNav" data-v-9d8abc1e data-v-7ad780c2><div class="VPNavBar" data-v-7ad780c2 data-v-5befd255><div class="container" data-v-5befd255><div class="title" data-v-5befd255><div class="VPNavBarTitle" data-v-5befd255 data-v-2973dbb4><a class="title" href="/" data-v-2973dbb4><!--[--><!--]--><!----><!--[-->Silence&#39;s blog<!--]--><!--[--><!--]--></a></div></div><div class="content" data-v-5befd255><div class="curtain" data-v-5befd255></div><div class="content-body" data-v-5befd255><!--[--><!--]--><div class="VPNavBarSearch search" data-v-5befd255><!--[--><!----><div id="local-search"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg class="DocSearch-Search-Icon" width="20" height="20" viewBox="0 0 20 20" aria-label="search icon"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"><kbd class="DocSearch-Button-Key"></kbd><kbd class="DocSearch-Button-Key">K</kbd></span></button></div><!--]--></div><nav aria-labelledby="main-nav-aria-label" class="VPNavBarMenu menu" data-v-5befd255 data-v-f732b5d0><span id="main-nav-aria-label" class="visually-hidden" data-v-f732b5d0>Main Navigation</span><!--[--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/" tabindex="0" data-v-f732b5d0 data-v-cb318fec><!--[--><span data-v-cb318fec>Home</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pages/archives.html" tabindex="0" data-v-f732b5d0 data-v-cb318fec><!--[--><span data-v-cb318fec>Archives</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pages/tags.html" tabindex="0" data-v-f732b5d0 data-v-cb318fec><!--[--><span data-v-cb318fec>Tags</span><!--]--></a><!--]--><!--[--><a class="VPLink link VPNavBarMenuLink" href="/pages/about.html" tabindex="0" data-v-f732b5d0 data-v-cb318fec><!--[--><span data-v-cb318fec>About</span><!--]--></a><!--]--><!--]--></nav><!----><div class="VPNavBarAppearance appearance" data-v-5befd255 data-v-283b26e9><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to light theme" aria-checked="true" data-v-283b26e9 data-v-70af5d02 data-v-1c29e291><span class="check" data-v-1c29e291><span class="icon" data-v-1c29e291><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-70af5d02><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-70af5d02><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div><!----><div class="VPFlyout VPNavBarExtra extra" data-v-5befd255 data-v-8e87c032 data-v-aa8de344><button type="button" class="button" aria-haspopup="true" aria-expanded="false" aria-label="extra navigation" data-v-aa8de344><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="icon" data-v-aa8de344><circle cx="12" cy="12" r="2"></circle><circle cx="19" cy="12" r="2"></circle><circle cx="5" cy="12" r="2"></circle></svg></button><div class="menu" data-v-aa8de344><div class="VPMenu" data-v-aa8de344 data-v-e42ed9b3><!----><!--[--><!--[--><!----><div class="group" data-v-8e87c032><div class="item appearance" data-v-8e87c032><p class="label" data-v-8e87c032>Appearance</p><div class="appearance-action" data-v-8e87c032><button class="VPSwitch VPSwitchAppearance" type="button" role="switch" title="Switch to light theme" aria-checked="true" data-v-8e87c032 data-v-70af5d02 data-v-1c29e291><span class="check" data-v-1c29e291><span class="icon" data-v-1c29e291><!--[--><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="sun" data-v-70af5d02><path d="M12,18c-3.3,0-6-2.7-6-6s2.7-6,6-6s6,2.7,6,6S15.3,18,12,18zM12,8c-2.2,0-4,1.8-4,4c0,2.2,1.8,4,4,4c2.2,0,4-1.8,4-4C16,9.8,14.2,8,12,8z"></path><path d="M12,4c-0.6,0-1-0.4-1-1V1c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,3.6,12.6,4,12,4z"></path><path d="M12,24c-0.6,0-1-0.4-1-1v-2c0-0.6,0.4-1,1-1s1,0.4,1,1v2C13,23.6,12.6,24,12,24z"></path><path d="M5.6,6.6c-0.3,0-0.5-0.1-0.7-0.3L3.5,4.9c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C6.2,6.5,5.9,6.6,5.6,6.6z"></path><path d="M19.8,20.8c-0.3,0-0.5-0.1-0.7-0.3l-1.4-1.4c-0.4-0.4-0.4-1,0-1.4s1-0.4,1.4,0l1.4,1.4c0.4,0.4,0.4,1,0,1.4C20.3,20.7,20,20.8,19.8,20.8z"></path><path d="M3,13H1c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S3.6,13,3,13z"></path><path d="M23,13h-2c-0.6,0-1-0.4-1-1s0.4-1,1-1h2c0.6,0,1,0.4,1,1S23.6,13,23,13z"></path><path d="M4.2,20.8c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C4.7,20.7,4.5,20.8,4.2,20.8z"></path><path d="M18.4,6.6c-0.3,0-0.5-0.1-0.7-0.3c-0.4-0.4-0.4-1,0-1.4l1.4-1.4c0.4-0.4,1-0.4,1.4,0s0.4,1,0,1.4l-1.4,1.4C18.9,6.5,18.6,6.6,18.4,6.6z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" viewbox="0 0 24 24" class="moon" data-v-70af5d02><path d="M12.1,22c-0.3,0-0.6,0-0.9,0c-5.5-0.5-9.5-5.4-9-10.9c0.4-4.8,4.2-8.6,9-9c0.4,0,0.8,0.2,1,0.5c0.2,0.3,0.2,0.8-0.1,1.1c-2,2.7-1.4,6.4,1.3,8.4c2.1,1.6,5,1.6,7.1,0c0.3-0.2,0.7-0.3,1.1-0.1c0.3,0.2,0.5,0.6,0.5,1c-0.2,2.7-1.5,5.1-3.6,6.8C16.6,21.2,14.4,22,12.1,22zM9.3,4.4c-2.9,1-5,3.6-5.2,6.8c-0.4,4.4,2.8,8.3,7.2,8.7c2.1,0.2,4.2-0.4,5.8-1.8c1.1-0.9,1.9-2.1,2.4-3.4c-2.5,0.9-5.3,0.5-7.5-1.1C9.2,11.4,8.1,7.7,9.3,4.4z"></path></svg><!--]--></span></span></button></div></div></div><!----><!--]--><!--]--></div></div></div><!--[--><!--]--><button type="button" class="VPNavBarHamburger hamburger" aria-label="mobile navigation" aria-expanded="false" aria-controls="VPNavScreen" data-v-5befd255 data-v-6bee1efd><span class="container" data-v-6bee1efd><span class="top" data-v-6bee1efd></span><span class="middle" data-v-6bee1efd></span><span class="bottom" data-v-6bee1efd></span></span></button></div></div></div></div><!----></header><div class="VPLocalNav fixed reached-top" data-v-9d8abc1e data-v-f8a0b38a><!----><div class="VPLocalNavOutlineDropdown" style="--vp-vh:0px;" data-v-f8a0b38a data-v-24251f6f><button data-v-24251f6f>Return to top</button><!----></div></div><!----><div class="VPContent" id="VPContent" data-v-9d8abc1e data-v-3cf691b6><div class="VPDoc has-aside" data-v-3cf691b6 data-v-a3c25e27><!--[--><!--]--><div class="container" data-v-a3c25e27><div class="aside" data-v-a3c25e27><div class="aside-curtain" data-v-a3c25e27></div><div class="aside-container" data-v-a3c25e27><div class="aside-content" data-v-a3c25e27><div class="VPDocAside" data-v-a3c25e27 data-v-cb998dce><!--[--><!--]--><!--[--><!--]--><div class="VPDocAsideOutline" role="navigation" data-v-cb998dce data-v-3a6c4994><div class="content" data-v-3a6c4994><div class="outline-marker" data-v-3a6c4994></div><div class="outline-title" role="heading" aria-level="2" data-v-3a6c4994>文章摘要</div><nav aria-labelledby="doc-outline-aria-label" data-v-3a6c4994><span class="visually-hidden" id="doc-outline-aria-label" data-v-3a6c4994> Table of Contents for current page </span><ul class="root" data-v-3a6c4994 data-v-463da30f><!--[--><!--]--></ul></nav></div></div><!--[--><!--]--><div class="spacer" data-v-cb998dce></div><!--[--><!--]--><!----><!--[--><!--]--><!--[--><!--]--></div></div></div></div><div class="content" data-v-a3c25e27><div class="content-container" data-v-a3c25e27><!--[--><!--]--><!----><main class="main" data-v-a3c25e27><div style="position:relative;" class="vp-doc _posts_FlashAttn" data-v-a3c25e27><div><p>参考<a href="https://arxiv.org/abs/2205.14135" target="_blank" rel="noreferrer"><em>FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</em></a>，事实上本文仅关心训练速度，并未在<code>Attention</code>计算上进行操作。</p><h2 id="面临问题" tabindex="-1">面临问题 <a class="header-anchor" href="#面临问题" aria-label="Permalink to &quot;面临问题&quot;">​</a></h2><p><code>Transformer</code> 框架由于核心组件<code>self-attention</code>对耗时及内存占用上都是序列长度<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="3.119ex" height="1.887ex" role="img" focusable="false" viewBox="0 -833.9 1378.8 833.9" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(975.3,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><msup><mi>N</mi><mn>2</mn></msup></math></mjx-assistive-mml></mjx-container>复杂度，很难将其应用到较长的上下文中，<code>FlashAttn</code>使得<code>Transformer</code>能够建模长序列，这带来以下几个好处：</p><ul><li>扩展功能： 使得NLP不仅能够处理段落，同时可以理解书籍、说明书等。</li><li>逼近现实： 例如CV上更高的分辨率意味着更好、更强的洞察力</li><li>开拓新领域： audio.video,medical imaging data</li></ul><h2 id="gpu" tabindex="-1">GPU <a class="header-anchor" href="#gpu" aria-label="Permalink to &quot;GPU&quot;">​</a></h2><pre><code>补充GPU工作原理
</code></pre><p>计算过程中，首先将HBM中的数据加载和写入到SRAM中，在SRAM中完成计算将数据传回并写入HBM。</p><h2 id="解决思路" tabindex="-1">解决思路 <a class="header-anchor" href="#解决思路" aria-label="Permalink to &quot;解决思路&quot;">​</a></h2><h3 id="关键在减少对hbm的读写" tabindex="-1">关键在减少对HBM的读写 <a class="header-anchor" href="#关键在减少对hbm的读写" aria-label="Permalink to &quot;关键在减少对HBM的读写&quot;">​</a></h3><p>现有的方法(例如稀疏逼近，低秩逼近或者是它们的结合)着眼于减少FLOPS开销，而这些改进下的wall-clock speed 较原始框架并未有明显改进，这暗示了FLOPS并不是通常情况下的瓶颈。传统的<code>Self-Attn</code>过程需要重复的从HBM中进行R\W，<a href="https://arxiv.org/abs/2007.00072" target="_blank" rel="noreferrer"><em>Data Movement Is All You Need: A Case Study on Optimizing Transformers</em></a>一文中也说明了真正的bound在于Data move。<br> 本文 <strong>Fig1 right</strong> 中展示dropout mask甚至花费了更长的时间，这非常反常理，由于Mask阶段设计小浮点数的计算，但事实上过程中的读写量比矩阵大得多，这也反映了注意力组件的bound主要由于数据的R\W。</p><h3 id="如何减少hbm的读写" tabindex="-1">如何减少HBM的读写 <a class="header-anchor" href="#如何减少hbm的读写" aria-label="Permalink to &quot;如何减少HBM的读写&quot;">​</a></h3><p>本文主要方法为分块计算，依次将块加载到SRAM中进行运算并将分块运算的结果传回HBM中进行组合。此方法需要解决两个问题：</p><ul><li>没有完全 input 的情况下如何执行<code>softmax</code>操作</li><li>是否存在更小的向后传递的中间值替代传统方法传回的<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.05ex;" xmlns="http://www.w3.org/2000/svg" width="1.459ex" height="1.645ex" role="img" focusable="false" viewBox="0 -705 645 727" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D446" d="M308 24Q367 24 416 76T466 197Q466 260 414 284Q308 311 278 321T236 341Q176 383 176 462Q176 523 208 573T273 648Q302 673 343 688T407 704H418H425Q521 704 564 640Q565 640 577 653T603 682T623 704Q624 704 627 704T632 705Q645 705 645 698T617 577T585 459T569 456Q549 456 549 465Q549 471 550 475Q550 478 551 494T553 520Q553 554 544 579T526 616T501 641Q465 662 419 662Q362 662 313 616T263 510Q263 480 278 458T319 427Q323 425 389 408T456 390Q490 379 522 342T554 242Q554 216 546 186Q541 164 528 137T492 78T426 18T332 -20Q320 -22 298 -22Q199 -22 144 33L134 44L106 13Q83 -14 78 -18T65 -22Q52 -22 52 -14Q52 -11 110 221Q112 227 130 227H143Q149 221 149 216Q149 214 148 207T144 186T142 153Q144 114 160 87T203 47T255 29T308 24Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>S</mi></math></mjx-assistive-mml></mjx-container>, <mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:0;" xmlns="http://www.w3.org/2000/svg" width="1.699ex" height="1.545ex" role="img" focusable="false" viewBox="0 -683 751 683" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>P</mi></math></mjx-assistive-mml></mjx-container>(<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.566ex;" xmlns="http://www.w3.org/2000/svg" width="6.606ex" height="2.452ex" role="img" focusable="false" viewBox="0 -833.9 2919.8 1083.9" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msup" transform="translate(1152,0)"><g data-mml-node="mi"><path data-c="1D441" d="M234 637Q231 637 226 637Q201 637 196 638T191 649Q191 676 202 682Q204 683 299 683Q376 683 387 683T401 677Q612 181 616 168L670 381Q723 592 723 606Q723 633 659 637Q635 637 635 648Q635 650 637 660Q641 676 643 679T653 683Q656 683 684 682T767 680Q817 680 843 681T873 682Q888 682 888 672Q888 650 880 642Q878 637 858 637Q787 633 769 597L620 7Q618 0 599 0Q585 0 582 2Q579 5 453 305L326 604L261 344Q196 88 196 79Q201 46 268 46H278Q284 41 284 38T282 19Q278 6 272 0H259Q228 2 151 2Q123 2 100 2T63 2T46 1Q31 1 31 10Q31 14 34 26T39 40Q41 46 62 46Q130 49 150 85Q154 91 221 362L289 634Q287 635 234 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(975.3,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2530.8,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mi>O</mi><mo stretchy="false">(</mo><msup><mi>N</mi><mn>2</mn></msup><mo stretchy="false">)</mo></math></mjx-assistive-mml></mjx-container>)用于后续梯度的计算。</li></ul><p>解决上述问题主要采用了两个方法<code>Tiling</code>,<code>Recomputation</code>。</p><ul><li>Tiling: 在<code>Online softmax</code>的基础上将 Softmax 计算的中间产物与 Attn 结合，保证了分块计算的可行性。</li><li>Recomputation: 不存储前向传输的注意力矩阵，需要时在SRAM中重新计算。</li></ul><h3 id="实践" tabindex="-1">实践 <a class="header-anchor" href="#实践" aria-label="Permalink to &quot;实践&quot;">​</a></h3><p>关键在如何重写<code>CUDA</code>，使得能够控制在什么时刻 load 什么东西。</p><h2 id="实验成果" tabindex="-1">实验成果 <a class="header-anchor" href="#实验成果" aria-label="Permalink to &quot;实验成果&quot;">​</a></h2><h3 id="speed-up" tabindex="-1">Speed up <a class="header-anchor" href="#speed-up" aria-label="Permalink to &quot;Speed up&quot;">​</a></h3><ul><li><strong>Fig2</strong>: 对比传统的<code>Attn</code>，尽管<code>FlashAttn</code>在增加计算(如后向传播中的重新计算)，但HBM的读写仅为传统方法的<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.816ex;" xmlns="http://www.w3.org/2000/svg" width="1.795ex" height="2.773ex" role="img" focusable="false" viewBox="0 -864.9 793.6 1225.5" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="39" d="M352 287Q304 211 232 211Q154 211 104 270T44 396Q42 412 42 436V444Q42 537 111 606Q171 666 243 666Q245 666 249 666T257 665H261Q273 665 286 663T323 651T370 619T413 560Q456 472 456 334Q456 194 396 97Q361 41 312 10T208 -22Q147 -22 108 7T68 93T121 149Q143 149 158 135T173 96Q173 78 164 65T148 49T135 44L131 43Q131 41 138 37T164 27T206 22H212Q272 22 313 86Q352 142 352 280V287ZM244 248Q292 248 321 297T351 430Q351 508 343 542Q341 552 337 562T323 588T293 615T246 625Q208 625 181 598Q160 576 154 546T147 441Q147 358 152 329T172 282Q197 248 244 248Z" style="stroke-width:3;"></path></g><rect width="553.6" height="60" x="120" y="220"></rect></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mfrac><mn>1</mn><mn>9</mn></mfrac></math></mjx-assistive-mml></mjx-container>，速度上提升了6倍。</li><li><strong>E.5</strong>: 在不同的GPU下，不同的组件(是否含有Mask,Dropout)，不同序列长度的所有情况下，<code>FlashAttention</code>较基准情况加速<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.186ex;" xmlns="http://www.w3.org/2000/svg" width="5.028ex" height="1.717ex" role="img" focusable="false" viewBox="0 -677 2222.4 759" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(722.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1722.4,0)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2</mn><mo>−</mo><mn>4</mn></math></mjx-assistive-mml></mjx-container>倍。</li><li><strong>4.1 BERT</strong>: 达到一定精度所需要的训练时间更短。比创下Nvida记录的MLPerf 1.1 加速了15%。</li><li><strong>GPT-2</strong>: 在GPT-2 small 和 GPT-2 midium 数据集上与Huggingface 和 Megatron-LM 对比，保持同等精度且速度较Huggingface为<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.186ex;" xmlns="http://www.w3.org/2000/svg" width="10.309ex" height="1.692ex" role="img" focusable="false" viewBox="0 -666 4556.4 748" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1500.2,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(2500.4,0)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" style="stroke-width:3;"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)" style="stroke-width:3;"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(778,0)" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3778.4,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>2.0</mn><mo>−</mo><mn>3.5</mn><mo>×</mo></math></mjx-assistive-mml></mjx-container>。</li></ul><h3 id="longer-sequences" tabindex="-1">Longer Sequences <a class="header-anchor" href="#longer-sequences" aria-label="Permalink to &quot;Longer Sequences&quot;">​</a></h3><ul><li><strong>4.2 LM with Long Context</strong>: 通常增长上下文的长度后训练速度会变慢但可以得到一个更好的模型(<strong>Table 5</strong> 展示了在更长的上下文训练的模型具备更高的分类精度)。列表展示了<code>FlashAttn</code>在<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.31ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 1021 705" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>4</mn><mi>k</mi></math></mjx-assistive-mml></mjx-container>文本长度的情况下具备比<mjx-container class="MathJax" jax="SVG" style="direction:ltr;position:relative;"><svg style="overflow:visible;min-height:1px;min-width:1px;vertical-align:-0.025ex;" xmlns="http://www.w3.org/2000/svg" width="2.31ex" height="1.595ex" role="img" focusable="false" viewBox="0 -694 1021 705" aria-hidden="true"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D458" d="M121 647Q121 657 125 670T137 683Q138 683 209 688T282 694Q294 694 294 686Q294 679 244 477Q194 279 194 272Q213 282 223 291Q247 309 292 354T362 415Q402 442 438 442Q468 442 485 423T503 369Q503 344 496 327T477 302T456 291T438 288Q418 288 406 299T394 328Q394 353 410 369T442 390L458 393Q446 405 434 405H430Q398 402 367 380T294 316T228 255Q230 254 243 252T267 246T293 238T320 224T342 206T359 180T365 147Q365 130 360 106T354 66Q354 26 381 26Q429 26 459 145Q461 153 479 153H483Q499 153 499 144Q499 139 496 130Q455 -11 378 -11Q333 -11 305 15T277 90Q277 108 280 121T283 145Q283 167 269 183T234 206T200 217T182 220H180Q168 178 159 139T145 81T136 44T129 20T122 7T111 -2Q98 -11 83 -11Q66 -11 57 -1T48 16Q48 26 85 176T158 471L195 616Q196 629 188 632T149 637H144Q134 637 131 637T124 640T121 647Z" style="stroke-width:3;"></path></g></g></g></svg><mjx-assistive-mml unselectable="on" display="inline" style="top:0px;left:0px;clip:rect(1px, 1px, 1px, 1px);-webkit-touch-callout:none;-webkit-user-select:none;-khtml-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;position:absolute;padding:1px 0px 0px 0px;border:0px;display:block;width:auto;overflow:hidden;"><math xmlns="http://www.w3.org/1998/Math/MathML"><mn>1</mn><mi>k</mi></math></mjx-assistive-mml></mjx-container>文本长度下<code>Megatron-LM</code>更快的训练速度，更长的序列代表模型更高的质量。</li><li>第一个解决<code>Path-X</code>的<code>Transformer</code>。</li></ul></div></div></main><footer class="VPDocFooter" data-v-a3c25e27 data-v-b4b63abf><!--[--><!--]--><!----><!----></footer><!--[--><!--]--></div></div></div><!--[--><!--]--></div></div><!----><!--[--><!--]--></div><div class="site-footer"> MIT Licensed | Copyright © 2021-2022 <a class="vitepress" href="https://github.com/Silence020922">Silence&#39;s blog</a><br> Powered by <a class="vitepress" target="_blank" href="//vitepress.vuejs.org/">VitePress - 1.0.0-rc.25</a> Theme by <a class="vitepress" target="_blank" href="//github.com/airene/vitepress-blog-pure">Vitepress-blog</a></div><!--]--></div>
    <script>window.__VP_HASH_MAP__=JSON.parse("{\"pages_archives.md\":\"Y4x88mh_\",\"pages_about.md\":\"zm3AryHG\",\"pages_tags.md\":\"_H06iygS\",\"index.md\":\"KdBfAfwO\",\"page_2.md\":\"hg-DmTYW\",\"page_3.md\":\"IXVU8ZT_\",\"posts_flashattn.md\":\"uZGWk_Tb\",\"posts_transformer.md\":\"VJ7DBgZ_\",\"posts_vitepress-first.md\":\"a_Ol6IXs\",\"posts_vllm.md\":\"l3wB_VjQ\",\"posts_theme-r.md\":\"hHO1s_cX\",\"posts_gnn-gcn.md\":\"RaQ93kzt\",\"posts_gnn-agcn.md\":\"Vz13XZAC\",\"posts_gnn-introduction.md\":\"jRIVIQSk\",\"posts_gnn-acmp.md\":\"hd-s1wPg\",\"posts_gnn-rayleigh.md\":\"Bnj_EVuk\",\"posts_gnn-gcnii.md\":\"MvB5eTTc\",\"posts_gnn-chebyshev.md\":\"pZNoeOVL\",\"posts_pag.md\":\"lUg7yX_N\",\"posts_combinatorial_optimizition.md\":\"NUFb2FHH\",\"posts_gc-gceffects.md\":\"VbGvxQ5L\"}");window.__VP_SITE_DATA__=JSON.parse("{\"lang\":\"en-US\",\"dir\":\"ltr\",\"title\":\"Silence's blog\",\"description\":\"Silence's blog\",\"base\":\"/\",\"head\":[],\"router\":{\"prefetchLinks\":true},\"appearance\":\"dark\",\"themeConfig\":{\"posts\":[{\"frontMatter\":{\"date\":\"2024-02-27\",\"title\":\"Transformer\",\"tags\":[\"LLM\"],\"description\":\"参考论文 Attention is all you need\"},\"regularPath\":\"/posts/Transformer.html\"},{\"frontMatter\":{\"date\":\"2024-02-21\",\"title\":\"vLLM\",\"tags\":[\"LLM\"],\"description\":\"LLM增添内存管理，利用PagedAttention，提高服务器吞吐量。\"},\"regularPath\":\"/posts/vLLM.html\"},{\"frontMatter\":{\"date\":\"2024-02-21\",\"title\":\"FlashAttention\",\"tags\":[\"LLM\"],\"description\":\"加速transormer模型训练速度，以便应用到较长上下文中。\"},\"regularPath\":\"/posts/FlashAttn.html\"},{\"frontMatter\":{\"date\":\"2024-01-21\",\"title\":\"Preferential Attachment Graph\",\"tags\":[\"Random grpah\",\"Preferential Attachment Graph\"],\"description\":\"反应现实世界幂律分布现象的一种随机图的定义及性质。\"},\"regularPath\":\"/posts/PAG.html\"},{\"frontMatter\":{\"date\":\"2024-01-08\",\"title\":\"Combinatorial Optimizition\",\"tags\":[\"Combinatorial Optimizition notes\"],\"description\":\"组合优化课程笔记\"},\"regularPath\":\"/posts/Combinatorial_Optimizition.html\"},{\"frontMatter\":{\"date\":\"2024-01-04\",\"title\":\"Effects of GC\",\"tags\":[\"GNN\"],\"description\":\"8-th，自GNN面世后，衍生了很多的变式，也存在很多实际的应用。但对向神经网络中添加卷积算子的意义本身，却缺乏理论上的证明，本文将携带卷积算子的神经网络与不使用图信息的神经网络进行对比，从理论出发给出严密的证明。参考Effects of graph convolutions in multi-layer networks\"},\"regularPath\":\"/posts/GC-GCEffects.html\"},{\"frontMatter\":{\"date\":\"2023-12-10\",\"title\":\"ACMP\",\"tags\":[\"GNN\"],\"description\":\"7-th，本文从神经信息传递的角度推到出模型并从能量函数的角度给出理论证明。参考Acmp:Allen-cahn message passing with attractive and repulsive forces for graph neural networks\"},\"regularPath\":\"/posts/GNN-ACMP.html\"},{\"frontMatter\":{\"date\":\"2023-12-09\",\"title\":\"GCNII\",\"tags\":[\"GNN\"],\"description\":\"6-th,参考SEMI-surperised classification with graph convolutional networks\"},\"regularPath\":\"/posts/GNN-GCNII.html\"},{\"frontMatter\":{\"date\":\"2023-12-05\",\"title\":\"AGCN\",\"tags\":[\"GNN\"],\"description\":\"5-th,考虑到在GCN模型中，由于表达与邻接矩阵直接相关，邻居节点的重要性由中心节点一圈一圈向外散布，这限制了卷积核的flexibility。这里考虑通过学习广义马氏距离替代邻接矩阵，实现对拉普拉斯矩阵的参数化设计，增加模型的表达能力。参考Adaptive Graph Convolutional Neural Networks。\"},\"regularPath\":\"/posts/GNN-AGCN.html\"},{\"frontMatter\":{\"date\":\"2023-12-04\",\"title\":\"GCN\",\"tags\":[\"GNN\"],\"description\":\"4-th,参考SEMI-surperised classification with graph convolutional networks\"},\"regularPath\":\"/posts/GNN-GCN.html\"},{\"frontMatter\":{\"date\":\"2023-12-03\",\"title\":\"Eigenvalues of the Laplacian\",\"tags\":[\"Rayleigh quotient\",\"Laplacian matrix\"],\"description\":\"3-rd,给出拉普拉斯矩阵特征值范围[0,2]的证明。\"},\"regularPath\":\"/posts/GNN-Rayleigh.html\"},{\"frontMatter\":{\"date\":\"2023-11-30\",\"title\":\"ChebNet\",\"tags\":[\"GNN\",\"Chebyshev\"],\"description\":\"2-nd,参考Convolution Neural Networks on Graphs with Fast Localized Spectral Filtering\"},\"regularPath\":\"/posts/GNN-Chebyshev.html\"},{\"frontMatter\":{\"date\":\"2023-11-29\",\"title\":\"Basic graph convolution operator\",\"tags\":[\"GNN\",\"GSP\"],\"description\":\"1-st，参考《深入浅出图神经网络》。\"},\"regularPath\":\"/posts/GNN-introduction.html\"},{\"frontMatter\":{\"title\":\"R语言入门\",\"date\":\"2022-10-17\",\"tags\":[\"R\"],\"description\":\"专业课——统计软件的随笔，这里使用的参考书目是《R语言实战(第二版)》\"},\"regularPath\":\"/posts/theme-R.html\"},{\"frontMatter\":{\"date\":\"2021-06-30\",\"title\":\"一直想找一个系统架构和设计都足够干净的系统\",\"tags\":[\"vitepress\",\"markdown\"],\"description\":\"vitepress的markdown插件支持的语法，一直想找一个干净的系统架构和设计都足够干净都，一直没满意的，不满意就自己设计，一直想找一个干净的系统架构和设计都足够干净都，一直没满意的，不满意就自己设计\"},\"regularPath\":\"/posts/vitepress-first.html\"}],\"website\":\"https://github.com/Silence020922\",\"nav\":[{\"text\":\"Home\",\"link\":\"/\"},{\"text\":\"Archives\",\"link\":\"/pages/archives\"},{\"text\":\"Tags\",\"link\":\"/pages/tags\"},{\"text\":\"About\",\"link\":\"/pages/about\"}],\"search\":{\"provider\":\"local\"},\"outlineTitle\":\"文章摘要\"},\"locales\":{},\"scrollOffset\":90,\"cleanUrls\":false}");</script>
    
  </body>
</html>